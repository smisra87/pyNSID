{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n================================================================================\n01. Writing a sid Dataset to file in NSID format\n================================================================================\n\n**Gerd Duscher**\n\n08/24/2020\n\n**this file shows how to store quickly store a sid Dataset to NSID format**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introduction\n -------------\n Saving a data and their metadata to file in a comprehensive way after acquisition, as intermediate or final results\n is at the core of any data analysis.\n The NSID data format is an attempt to meet those requirement as painless and universal as possible.\n In the following, we will create a sid.Dataset from a numpy array, which we will store as NSID format in its HDF5 file\n#######################################################################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import numpy and h5py as the basis for the following operation\nimport numpy as np\nimport h5py\n\n# All data analysis in pycroscopy is based on sid.Datasets\nimport sidpy as sid\n\n# Utilize the NSID package for writing\nimport sys\nsys.path.append('../pyNSID/')\nimport pyNSID as nsid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making a sid Dataset (which is based on dask) is described in the sid Documentation\nHere, we just make a basic sid.Dataset from a numpy array\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_set = sid.Dataset.from_array(np.zeros([4, 5, 10]), name='zeros')\nprint(data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a HDF5 file and groups using h5py is described in the h5py_primer in this directory\nFor testing reasons, we first delete the Channel_000 group\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_file = h5py.File(\"zeros.hf5\", mode='a')\nif 'Measurement_000' in h5_file:\n    del h5_file['Measurement_000/Channel_000']\nh5_group = h5_file.create_group('Measurement_000/Channel_000')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write this sid.Dataset to file with one simple command\nWe use the sid hdf_utilities to look at the created h5py file structure\n\nPlease note that the NSID dataset has the dimensions (a,b,c) attached as attributes,\nwhich are accessible through \"h5_dataset.dims\". Look at hf5py for more information.\n\nThe HDF55 group \"original_metadata\" contains contain all the information of the original file as a dictionary type\nin the attributes original_metadata.attrs (here empty)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_dataset = nsid.hdf_io.write_nsid_dataset(data_set, h5_group, main_data_name='zeros')\n\nsid.hdf.hdf_utils.print_tree(h5_file)\n\nprint('dimension of hdf5 dataset: ', h5_dataset.dims)\nprint('name of hdf5 dataset: ', h5_dataset.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read NSID Dataset into sid.Dataset with two simple command\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reader = nsid.NSIDReader(h5_group)\nsid_datasets = reader.read()\n\n# Let's see what we got\nfor i, dataset in enumerate(sid_datasets):\n    print(dataset.title)\nprint('read sidpy dataset 1 - printing associated axis a: ', sid_datasets[0].a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we can also read any specific h5py dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = reader.read_h5py_dataset(h5_group['zeros'])\n\nprint(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A result can entail just some values or properties which are most effectivly stored in a dictionary.\nAlternatively, the results are another dataset, or both.\nHere we just add 1 to our dataset and write it to disc.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = {'added': 1}\nresult_dataset = dataset.like_data(dataset+1)\nresult_dataset.title = 'ones'\nresult_dataset.source = dataset.title\nprint('source', result_dataset.source, dataset.title)\n\nresults_group = nsid.hdf_io.write_results(h5_group, dataset=result_dataset, attributes=results, process_name = 'add one')\nprint(results_group)\n\nsid.hdf.hdf_utils.print_tree(h5_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we read the file again, we get an additional main dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sid_datasets = reader.read()\n\n# Let's see what we got\nfor i, dataset in enumerate(sid_datasets):\n    print(dataset.title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end of our program, we need to close the h5py file.\nWe cannot close it earlier in case the sidoy dataset is large and then will be only read on demand.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_group.file.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}